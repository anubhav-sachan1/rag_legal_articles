{
    "distances": [
        [
            0.7055919170379639,
            0.7335958480834961,
            0.7734811305999756,
            0.8144334554672241,
            0.8400313258171082,
            0.8445643186569214,
            0.8556840419769287,
            0.8684060573577881,
            0.8703514933586121,
            0.8887780904769897
        ]
    ],
    "results": [
        "The ICO also spearheads the Regulators and AI Working Group, a platform fostering dialogue among various regulators and public authorities.\n\nThe collaborative approach adopted in the UK is notable within the European regulatory landscape.\n\nUnlike many jurisdictions where regulators operate independently, the UK stands out for fostering partnerships among various regulatory bodies.\n\nThis cross-sectoral approach to AI allows for the sharing of expertise and responsibilities across different bodies, facilitating a more comprehensive and coordinated oversight of AI technologies.\n\nNext Steps The UK government will now review the Strategy along with strategies provided by other regulators 4 to determine whether stand-alone or amended AI legislation is required in the UK.\n\nGiven the responses of regulators to date (see, in particular, our 2 May 2024 client alert \u201c UK Regulators Publish Approaches to AI Regulation in Financial Services \u201d), it seems unlikely the UK government will implement far-reaching AI regulation anytime soon, with perhaps the exception of some specific high-risk and potentially harmful use cases.\n\nTherefore, as the legal framework, guidance and resourcing on AI in the UK develops, is it likely that the ICO will play a central role in setting out key principles, monitoring compliance and implementing enforcement action as the de facto lead regulator for AI. _______________ 1\n\nThe paper was in response to a 15 February 2024 request by the secretary of state for Science, Innovation and Technology .\n\n2 See ICO news releases on actions announced on 23 February 2024 and 23 May 2022 .\n\n3\n\nIn addition to audits specific to the UK\u2019s General Data Protection Regulation (GDPR), the ICO is also conducting audits related to other legislation, such as the Privacy and Electronic Communications Regulations (PECR), the Network and Information Systems Regulations 2018 (NIS) and areas where information rights overlap with legislation such as the Digital Economy Act (DEA).\n\n4 See strategies by the Prudential Regulation Authority/Bank of England , FCA , Ofcom and CMA .\n\nThis memorandum is provided by Skadden, Arps, Slate, Meagher & Flom LLP and its affiliates for educational and informational purposes only and is not intended and should not be construed as legal advice.\n\nThis memorandum is considered advertising under applicable state laws.",
        "While still unclear, this may mean that administrative fines will be reserved for more serious violations instead of remedial actions, audits or monitoring.\n\nUnlike the decision to relax public authority enforcement for two years, the ICO  has not communicated the same with respect to private sector businesses.\n\nThis may signal the start of a sector-specific approach to enforcement by the ICO, especially given the information commissioner\u2019s comments on topic.\n\nAI-Driven Discrimination The ICO will further examine how to combat AI-driven discrimination by sharing updated guidance with AI developers to ensure their software algorithms treat people and their information fairly, while also seeking to actively investigate circumstances where AI is having a discriminatory effect ( e.g ., AI tools used for recruitment or eligibility for financial support).\n\nGiven the increased use of AI in automated business processes, companies may increasingly want a commitment from their suppliers that they have taken steps to ensure their AI is nondiscriminatory.\n\nChildren In line with U.K. government initiatives ( e.g ., the Online Safety Bill), the ICO has continued to focus on children\u2019s privacy rights, in particular in relation to internet-based interactions.\n\nWhile there will be a heavier focus on social media platforms, video and music streaming sites and gaming platforms, any business with an online presence will have an obligation to ensure that children have an age-appropriate online experience.\n\nKey Takeaways Determining whether \u2014 and to what extent \u2014 the plans described in ICO25 will have a positive effect on business will be determined by how the ICO roll out their strategies.\n\nFrom the plans the ICO has shared to date, we can note: Whilst the ICO\u2019s plans include a commitment to implement a package of actions that are intended to reduce the cost and complexity of data protection compliance for businesses, the ICO25 announcement was accompanied by a clear warning to those that misuse personal data.\n\nThe information commissioner also noted that upcoming legal reforms 7 to the U.K.\u2019s data protection regime will allow the ICO to devote more of its resources towards discretionary matters and internally generated investigations ( e.g ., into predatory marketing), whereas a significant proportion of its current workload is dedicated to responding to complaints.\n\nIn the July 2022 Data Protection Practitioner\u2019s Conference, the information commissioner flagged his interest in broadening its scope to determine data subjects\u2019 compensation claims (which are currently resolved via litigation).\n\nGiven that a number of ICO25 key performance indicators focus on response and resolution timings, it will be interesting to see how the ICO intends to manage these potential increases to its caseload volume.\n\n_______________ 1\n\nThe blog post is available here .\n\n2\n\nThe settlement agreement is available here .\n\n3\n\nThe consultation is available here .\n\n4 See our January 2022 Privacy & Cybersecurity Update article \u201c UK Government Publishes National Cyber Strategy \u201d and our June 2022 Privacy & Cybersecurity Update article \u201c UK Government Announces a Six-Point Digital Strategy .\u201d\n\n5\n\nThe report is available here .\n\n6 ICO25 is available here .\n\n7 See our May 2022 Privacy & Cybersecurity Update article \u201c Queen\u2019s Speech Confirms Planned Overhaul of UK Data Protection Regime .\u201d\n\nThis memorandum is provided by Skadden, Arps, Slate, Meagher & Flom LLP and its affiliates for educational and informational purposes only and is not intended and should not be construed as legal advice.\n\nThis memorandum is considered advertising under applicable state laws.",
        "Final CPRA Regulations Anticipated To Take Effect in April 2023\n\nThe California Privacy Protection Agency (CPPA) has indicated that it will not issue final regulations implementing the California Privacy Rights Act (CPRA) until late January or early February 2023, meaning the final regulations likely will not take effect until at least April 2023.\n\nOn January 23, 2023, the CPPA announced that the agency will hold a public meeting on February 3, 2023, to discuss the status of its rulemaking process for the CPRA, setting off a timeline that seems likely to result in final regulations that will be enforceable in April 2023.\n\nAs described in greater detail in our November 2022 Privacy & Cybersecurity Update , although the CPRA became enforceable on January 1, 2023, the CPPA was unable to develop and approve final regulations before that date.\n\nIf, as expected, the CPPA submits final regulations to its board in early February and the board approves the draft, the agency can submit the final rulemaking package to the California Office of Administrative Law (OAL) in mid-February.\n\nThe OAL would then have 30 working days to approve or disapprove the regulations, and upon their approval, the draft regulations will become final.\n\nThus, board members have stated that the soonest the regulations could take effect is in April.\n\nCivil and administrative enforcement of the CPRA was originally set to commence on July 1, 2023.\n\nHowever, the CPPA board has discussed the need to act as a \u201creasonable enforcer\u201d and provide leniency to businesses that have made good-faith efforts to comply with the regulations given the uncertainty regarding when the regulations will be finalized and the limited time remaining for businesses to adjust their compliance posture.\n\nFurthermore, the most recent proposed CPRA regulations indicate that enforcement may be further delayed on a case-by-case basis.\n\nSpecifically, the proposed regulations stated that the CPPA \u201cmay consider all facts it determines to be relevant, including the amount of time between the effective date of the statutory or regulatory requirement(s) and the possible or alleged violation(s) of those requirements, and good faith efforts to comply with those requirements.\u201d\n\nOnce the current rulemaking package, which is only a partial set of regulations, is finalized, we expect additional regulations related to automated decision-making, cybersecurity audits and privacy risk assessments in the near future.\n\nKey Takeaways Until the new regulations are finalized, companies should ensure that they comply with existing California Consumer Privacy Act regulations.\n\nHowever, as some CPPA board members have indicated that they do not expect major revisions to the most recent CPRA draft regulations and that the enforcers may provide leniency to businesses that have made good-faith efforts to comply with the regulations, companies should be preparing to comply with the CPRA\u2019s regulations as well.\n\nUK Information Commissioner\u2019s Office Publishes Names of Organizations Subject to Data Breaches, Complaints and Investigations\n\nThe U.K.\u2019s Information Commissioner\u2019s Office (ICO) has published a range of data sets on its website that identify organizations that have self-reported personal data breaches, that were the subject of data protection complaints, and that were under investigation by the ICO.\n\nIn December 2022, in a change of policy, the ICO published numerous data sets relating to self-reported personal data breaches, data protection complaints from members of the public and investigations by the ICO for breaches of U.K. data protection laws (including the U.K. GDPR, the U.K. Data Protection Act 2018, and the Privacy and Electronic Communications Regulations 2003 (PECR)).",
        "ICO25 is open to public consultation until September 22, 2022.\n\nBackground Information Commissioner John Edwards launched ICO25 in a speech that highlighted both the (1) opportunities to private sector businesses in \u201cempowering organisations to use information responsibly and confidently to invest and innovate\u201d and \u201cempowering people to confidently share their information to use the products and services that drive our economy and society,\u201d by creating more clarity and certainty with respect to compliance and enforcement, and (2) risks to noncompliant private sector businesses of being \u201con the receiving end of [the ICO\u2019s] most punitive tools,\u201d which aligns with the U.K. government\u2019s intention to raise the maximum level of Privacy and Electronic Communications Regulations (PECR) fines to those outlined under the U.K. GDPR.\n\nKey ICO25 Initiatives for the Private Sector ICO25 covers a broad range of initiatives, including the following from a private sector business perspective: Affordable and User-Friendly Compliance Tools\n\nThe ICO proposes to reduce business data protection compliance costs by providing the following: Training Materials.\n\nOn its website, the ICO will publish its existing internal data protection and freedom of information training materials, along with a newly developed range of \u201cdata essentials\u201d training materials aimed at small- and medium-sized businesses for which data processing does not form a part of their core activities.\n\nAdvice Database.\n\nThe ICO will create a number of databases of the advice provided to businesses, including the \u201cone-off\u201d advice provided to anonymous organizations and members of the public ( e.g ., through the ICO\u2019s free telephone service), and the recommendations made to organizations following complaints, investigations and audits.\n\nCompliance Templates.\n\nIn addition to those templates already made available on their website ( e.g ., the data protection impact assessment template), the ICO will produce a range of off-the-shelf products and templates to help organizations develop their own compliance programs.\n\nSector-Specific Advice.\n\nThe ICO will work with sector-specific ombudsman and representative groups to co-design tailored and targeted compliance advice for various sectors.\n\nSupport for Innovation.\n\nThe ICO will provide bespoke support and regulatory clarity to innovative businesses working with personal data, with the introduction of a new service called \u201ciAdvice.\u201d\n\nICO25 also notes the ICO\u2019s intention to develop a data subject access request (DSAR) tool to enable individuals to generate an instant DSAR.\n\nAccording to the ICO, this would make the process of requesting access to data simpler and clearer for both the data subject and the organization receiving the request.\n\nEnforcement Enforcement is an important ICO mechanism that aims to encourage data protection compliance and protect the most vulnerable data subjects.\n\nICO25 explains that the ICO will prioritize the following enforcement-related issues over the next year: Response and Resolution Times.\n\nICO25 includes a number of key performance indicators centered around response and resolution times for claims and investigations, including a commitment to conclude 95% of all formal investigations within 12 months, ensure 90% of audit recommendations are accepted in full or in part, to assess and respond to 80% of complaints from data subjects within 90 days, refer or close 80% of personal data breach reports within 30 days, and resolve 80% of written enquiries within seven days.\n\nTo meet these key performance indicators, the ICO may utilize its enforcement power to require businesses to be more responsive.\n\nApproach to Enforcement.\n\nICO25 notes that the agency will consider the potential risk posed or actual harm caused when selecting an enforcement action.\n\nWhile still unclear, this may mean that administrative fines will be reserved for more serious violations instead of remedial actions, audits or monitoring.",
        "The consultation seeks views on various questions and proposals aimed at improving defense, resilience and recovery factors, and asks respondents to assess the sector\u2019s risk management measures.\n\nIt also identifies a number of proposals that may be introduced under future regulations or legislation, including legal requirements regarding: defined and tested service continuity assurances and incident management plans, to be engaged in the result of system failures; appropriate and proportionate measures to identify and manage security and resilience risks; notification of a regulator in the event of a material outage or incident, or during the course of an investigation; accountability and governance, including a requirement to appoint a suitable individual at the board-level to oversee security and resilience; and penetration testing, including proposals that attempted breaches be carried out by government authorities or competent third parties.\n\nOriginally scheduled to close on July 24, 2022, the deadline to submit views has been extended and the consultation will now close on August 8, 2022.\n\nReview of NIS Regulations The consultation represents an important step in the government\u2019s push towards stricter regulation of data storage and processing infrastructure, with the results likely to underpin more significant government oversight of the sector in the future.\n\nIt is not the only step, however; in July 2022, the government published its second post-implementation review of the NIS 2018 Regulations, which were designed to protect digital and essential services from cyberattack.\n\n5\n\nThe review notes that there is \u201croom for improvement\u201d in the NIS Regulations, and proposes a number of amendments to the regulatory regime, including providing for greater flexibility in the scope of organizations under its purview, increased management of supply chain risk and greater resource allocation for enforcement.\n\nKey Takeaways The consultation and review of the NIS Regulations show a general trend towards heightened regulation of data infrastructure and also may serve as a reminder of the critical role that the government plays in the majority of businesses, regardless of size.\n\nOrganizations should ensure that operational and legal diligence processes are in place to evaluate data storage and processing providers, and that business units undertake regular reviews of relevant suppliers.\n\nUK Data Protection Regulator Announces Plan to Reduce Business Compliance Costs The U.K. Information Commissioner\u2019s Office (ICO) has announced a wide-ranging three-year plan for data protection, which includes measures designed to save businesses more than \u00a3100 million in privacy compliance costs.\n\nOn July 14, 2022, the ICO unveiled its high-level strategic objectives for the next three years, including a detailed action plan for October 2022 to October 2023.\n\n6\n\nIn keeping with the various sectors and stakeholders that the ICO governs, the plan \u2014 dubbed \u201cICO25\u201d \u2014 addresses a wide array of topics, ranging from safeguarding children\u2019s rights to addressing cost-of-living concerns.\n\nFor U.K. businesses and businesses that serve U.K.-based customers, key elements of ICO25 are the practical action items designed to save businesses over \u00a3100 million before 2025, including publication of templates and guidance designed to reduce the cost of compliance.\n\nICO25 is open to public consultation until September 22, 2022.",
        "Rather than specifically regulating artificial intelligence (AI), the UK government has opted to rely on the existing web of laws and regulations applying to technology across a spectrum of sectors in its jurisdiction.\n\nBut with this pro-innovation, principles-based approach comes questions that have remained unanswered.\n\nMany relate to the application of UK data privacy laws and how AI technology compliance can truly be achieved.\n\nOn 30 April 2024, the UK\u2019s Information Commissioner\u2019s Office (ICO) published Regulating AI: the ICO\u2019s Strategic Approach 1 (the Strategy), in which it details how the ICO is driving forward the principles in the 2023 AI regulation white paper and the government\u2019s 2024 guidance on implementing those principles .\n\nIt is clear that the ICO wants to remain a pragmatic regulator, acknowledging that \u201cdata protection law is risk-based\u201d and that risk should be \u201cmitigated\u201d but not \u201cnecessarily completely removed.\u201d\n\nBut whether that approach causes more uncertainty than comfort for industry participants remains an open question.\n\nThe Strategy The Strategy\u2019s most important takeaways include: The ICO is potentially a de facto AI regulator.\n\nThe general approach remains pragmatic and risk-focused.\n\nEnforcement action will be taken, where necessary.\n\nAI is a key focus area for the ICO.\n\nPartnerships and open dialogue with other regulators is essential.\n\nThe ICO Is Potentially a D e Facto AI Regulator Unlike the European Union, the UK government has not deemed it necessary to appoint an independent regulator to oversee all AI.\n\nHowever, in the Strategy, the ICO notes that many of the principles identified in the AI regulation white paper align with established data protection principles, e.g ., the transparency, fairness and accountability principles.\n\nData protection regulation also applies at all points of technology development, from privacy by design through to deployment and use.\n\nTherefore, the ICO is well placed to leverage the privacy principles to oversee unique challenges posed by AI technologies at every stage of the AI life cycle, and thereby potentially be a de facto AI regulator.\n\nThe General Approach Remains Pragmatic and Risk-Focused In the Strategy, the ICO recognises the huge potential benefits of AI but notes the associated inherent risks, many of which derive from how the data \u2014 specifically, personal data \u2014 is used in the development and deployment of AI systems.\n\nThat being said, the ICO makes clear statements in the Strategy that it is not seeking complete compliance of AI with UK data protection laws.\n\nIt states, for example, that \u201c[d]ata protection law is risk-based\u201d and \u201c[w]e require risks to be mitigated and managed \u2026 but not necessarily completely removed.\u201d\n\nIn assisting businesses in navigating potential risks and mitigants, the ICO references its AI and Data Protection Risk Toolkit .\n\nMany privacy leaders have been grappling with questions around topics such as transparency, purpose limitation and grounds to process in relation to the use of personal data in the development and use of AI.\n\nThe ICO does not give any specific answers to these questions.\n\nIt references consultations current and future, including a generative AI consultation series , but from the tone of the Strategy it does not seem likely that new specific AI privacy rules are on the horizon.\n\nThe ICO states that \u201cwhere organisations identify high risk to the rights and freedoms of individuals that \u2026 cannot [be] mitigate[d] sufficiently they are required to consult the ICO.\u201d\n\nHowever, \u201chigh risk\u201d to \u201crights and freedoms\u201d seems to be a high bar.\n\nThe Strategy suggests that the ICO will continue to be a pragmatic, risk-focused regulator, and that if the usual Data Privacy Impact Assessments are conducted and appropriate safeguards put in place, businesses will be free to experiment with and develop AI.",
        "Enforcement Action Will Be Taken, Where Necessary Despite the above, the ICO has made it clear that it will act to enforce data protection laws, and it has made particular reference to recent fines and an enforcement notice.\n\nThe enforcement examples it has sited relate to use of facial recognition technology 2 and protection of data relating to children \u2014 two particularly sensitive areas in data privacy.\n\nThe ICO actions make clear that while pro-innovation and pragmatism is supported, certain principles will not be ignored.\n\nAI Is a Key Focus Area for the ICO AI is one of the ICO\u2019s key focus areas for 2024-25, alongside children\u2019s privacy, ad-tech and online tracking.\n\nThe Strategy highlights some of the initiatives that the ICO has been undertaking to ensure responsible AI adoption and data protection compliance in the UK, and to enhance its understanding of the technology.\n\nBusinesses can expect more consultations, consensual audits and invitations to sandbox projects over the coming months and years.\n\nBusinesses engaging in higher-risk forms of AI, such as relating to biometric data, are also more likely to hear from the ICO, with potentially an increasing number of requests for information as the ICO learns how the technology works.\n\nICO initiatives include: Targeted consensual auditing.\n\nThe ICO has been actively conducting consensual audits of high-risk businesses ( i.e ., controllers identified based on reported breaches, number of complaints received by the ICO, annual statements and publicly available information, business intelligence, media reports and other relevant information) to assess their processing of personal data using AI.\n\nThese audits serve as an important educational tool, providing businesses with practical advice on how to improve their AI practices.\n\n3\n\nThe Strategy outlines that audits are currently underway for businesses offering AI-based age estimation and verification services, as well as AI-based products within the recruitment sector.\n\nAs part of this initiative, the ICO expects to publish a report later this year detailing findings from engagements with businesses.\n\nRegulatory sandbox projects.\n\nThe ICO has been engaging in regulatory sandbox projects to explore innovative AI applications while ensuring data protection compliance.\n\nThese projects provide cooperating businesses with a controlled environment in which to test new AI technologies, allowing the ICO to assess potential risks and further develop regulatory frameworks that reflect operational realities.\n\nKey industry stakeholders, including Big Tech, have already participated in these sandboxes and contributed meaningfully to the ICO\u2019s understanding of the potential and challenges of AI.\n\nPartnerships and Open Dialogue With Other Regulators Is Essential In the Strategy, the ICO has emphasised that active engagement and collaboration among regulators is crucial to holistically addressing AI-related challenges.\n\nFor example, the ICO\u2019s work as part of the Digital Regulation Cooperation Forum (DRCF) brings together the ICO, the Competition and Markets Authority (CMA), Ofcom (the UK\u2019s communications regulator) and the Financial Conduct Authority (FCA).\n\nThis forum seeks to establish a unified approach to digital regulation, fostering coherence in oversight and enforcement.\n\nWithin the DRCF, AI holds a prominent position on the agenda, and collaborative efforts have resulted in the publication of joint perspectives on AI benefits and harms, discussions on emergent technologies like generative AI, and research into the third-party auditing landscape.\n\nThe establishment of the \u201cAI and Digital Hub\u201d further enhances this cooperation, providing a platform for innovators to navigate regulatory complexities across multiple sectors.\n\nThe ICO also spearheads the Regulators and AI Working Group, a platform fostering dialogue among various regulators and public authorities.",
        "Under the current regime, businesses must conduct a DPIA before any large-scale processing of special category personal data is undertaken.\n\nThe consultation includes a proposal to allow businesses to adopt an approach that reflects their specific organizational circumstances.\n\nChanges to the data breach reporting threshold.\n\nWhile businesses must currently report any breach unless that breach is \u201cunlikely\u201d to result in a risk to the data subjects\u2019 rights, the consultation proposes that this threshold be amended so that reports need only be made if the risk is \u201cmaterial.\u201d\n\nThe consultation closed in November 2021 and with the results expected in the coming weeks and the draft bill to follow this summer.\n\nWhile it is clear that the reforms are intended to reduce administrative burdens on businesses and organizations, the Queen\u2019s Speech was unequivocal in stating that this would not come at the cost of the rights of individuals.\n\nIndeed, the government has stated that the bill will still ensure that \u201cUK citizens\u2019 personal data is protected to a gold standard\u201d and that the new \u201cculture of data protection\u201d will be \u201coutcomes-focused.\u201d\n\nOnce presented before Parliament, the bill will have an uncertain future as its passage through the legislative process will see months of review and debate, and also may be rejected without being passed into law.\n\nKey Takeaways\n\nThe reforms to the current data protection regime are expected to afford some level of flexibility to U.K. businesses, allowing for the implementation of data protection compliance programs and requirements over time.\n\nThe U.K. government estimates that the bill will generate over \u00a31 billion of savings in the 10 years following its introduction.\n\nThe reforms are expected to be particularly significant to new businesses, small and medium-sized enterprises, and technology start-ups that may lack the resources to keep up with the regulatory obligations currently imposed by the U.K. GDPR.\n\nFor others, however, considerable resources have already been invested regarding the implementation of detailed data protection compliance frameworks, with many businesses having taken on additional skilled personnel to manage and administer these programs.\n\nIn addition, for businesses that operate in both the U.K. and Europe (or who have customers in both territories), the bill may introduce unwelcome legislative divergence and increase the complexity of current compliance measures.\n\nFinally, in the event that the bill introduces significant changes to the U.K.\u2019s current regime, and those changes are tantamount to an erosion of individual rights, this may prompt the EU to review or even revoke the U.K.\u2019s adequacy decision.\n\nThis would mean that, much like current transfers of data from the U.K./EU to the U.S., transfers of data from the EU to the U.K. would need to be protected with additional safeguards (including contractual protections) that may further increase the administrative expense of trade between EU- and U.K.-based businesses.\n\nGlobal organizations should carefully monitor developments regarding the U.K.\u2019s data protection reforms to ensure that they are prepared in advance to respond to the changes, and we will provide updates on the status of the bill as further details emerge.\n\nUK Information Commissioner\u2019s Office Publishes Updates to Data Anonymization Guidance On March 7, 2022, the ICO published the latest chapter of its ongoing guidance on operational and organizational requirements for data protection law-compliant data anonymization (including personal data).\n\nThis is the fourth draft chapter of ICO guidance on this topic, with more anticipated to come.\n\nThe ICO is seeking views on all chapters until September 16, 2022, and, once finalized, the consolidated guidance will provide valuable insight into how the ICO will assess businesses\u2019 compliance with data protection laws.",
        "In releasing the statement, Samuel Levine, director of the FTC\u2019s Bureau of Consumer Protection, noted that \u201cstudents must be able to do their schoolwork without surveillance by companies looking to harvest their data to pad their bottom line,\u201d and \u201c[p]arents should not have to choose between their children\u2019s privacy and their participation in the digital classroom.\u201d\n\nKey Takeaways With the increase in use of edtech in public education, the FTC may be signaling a renewed interest in COPPA compliance and enforcement.\n\nEdtech providers and other COPPA-covered businesses should review the FTC\u2019s statement and ensure compliance with the COPPA Rule, while paying particular attention to the collection, use, retention and protection of children\u2019s personal information.\n\nQueen\u2019s Speech Confirms Planned Overhaul of UK Data Protection Regime On May 10, 2022 the U.K. government formally announced its intentions to proceed with reforms to the U.K.\u2019s data protection regime through the introduction of a new Data Reform Bill.\n\nThe announcement was made in the Queen\u2019s Speech, which sets out the government\u2019s yearly policy and legislative agenda for the new parliamentary session.\n\nWhile the precise content of the bill has not yet been confirmed, the Queen\u2019s Speech noted the government\u2019s view that \u201cthe UK General Data Protection Regulation and Data Protection Act 2018 are highly complex and prescriptive pieces of legislation \u2026\n\n[that] encourage excessive paperwork, and create burdens on businesses with little benefit to citizens.\u201d\n\nIt is therefore expected that the bill, once announced, will underscore the government\u2019s intention to implement a regulatory regime that departs significantly from the current U.K. GDPR.\n\nThe bill is expected to be presented in the summer of 2022, at which point it will begin its lengthy and uncertain passage through Parliament.\n\nBackground Reforms to the U.K.\u2019s data protection regime have been anticipated since September 2021, when the Department for Digital, Culture, Media and Sport (DCMS) published a new consultation entitled \u201cData: a new direction,\u201d 4 which included various proposals to reduce the burdens on U.K. businesses, including: Removal of the requirement to keep records of data processing activities.\n\nWhile the U.K. GDPR currently requires controllers to maintain records containing a number of mandatory categories of information ( e.g ., for purposes of data processing and retention periods for each category of data), the consultation recommends introducing greater flexibility for the form and content of these records.\n\nRemoval of the requirement to appoint a data protection officer (DPO).\n\nAt present, the U.K. GDPR mandates that businesses conducting certain high-risk forms of processing ( e.g ., processing of special category data on a large scale) must designate a DPO with \u201cexpert knowledge of data protection law and practices\u201d and register their details with the Information Commissioner\u2019s Office (ICO).\n\nThe consultation includes a proposal to instead allow businesses to internally designate an individual to oversee their data protection compliance programs.\n\nChanges to the regime on data subject rights requests.\n\nIn response to a perceived high administrative burden on businesses, the consultation has set out a number of proposed changes to the current rules on data subject rights requests, including the introduction of a cost ceiling ( i.e ., a limit to the amount of costs a business must incur when responding to a data subject rights request) and a reduction in the threshold that must be reached before a business can refuse to respond to a request (currently the request must be \u201cmanifestly unfounded\u201d).\n\nRemoval of the requirement to carry out data protection impact assessments (DPIAs).\n\nUnder the current regime, businesses must conduct a DPIA before any large-scale processing of special category personal data is undertaken.",
        "Information Commissioner John Edwards warned that if organizations do not regularly monitor for suspicious activities in their systems and fail to act on warnings, they can expect to face similar fines from the ICO.\n\nData Minimization Employers should not collect more data through employee monitoring than they need to achieve the purpose of such monitoring.\n\nThis is closely tied to the principle of purpose limitation (see above).\n\nThe guidance warns against the risks of \u201cfunction creep,\u201d whereby monitoring technologies gather wider categories and larger amounts of information than necessary to achieve their purpose.\n\nData Protection Impact Assessments Employers must complete a DPIA in cases where monitoring activities present a high risk to the rights and freedoms of employees ( e.g ., covert monitoring).\n\nEven where monitoring activities do not create such high risk, the ICO recommends employers conduct a DPIA as good practice.\n\nIn conducting a DPIA, employers should take into consideration the extent of employees\u2019 privacy expectations (which are likely to be greater when working from home than in the office), as well as the impact of the monitoring on the rights of employees and anyone else captured by the monitoring ( e.g ., the general public).\n\nAdditionally, best practices dictate that employers should consult employees as part of the DPIA.\n\nAccording to the guidance, employers must carry out a DPIA in cases where the monitoring involves: the use of analytics to make inferences, predictions or decisions about employees; processing biometric data to uniquely identify an individual; the use of facial recognition technologies; and any covert monitoring.\n\nAutomated Processes in Monitoring Tools\n\nThe guidance recognizes the business benefits of monitoring tools with automated processes or so-called \u201cpeople analytics\u201d ( e.g ., managing performance, monitoring absences).\n\nHowever, the ICO warns of the risks to employees\u2019 rights and freedoms from automated decision making ( i.e ., decision-making without human involvement) based on automated monitoring.\n\nThe guidance includes an example of an organization that bases employees\u2019 pay entirely on automated monitoring of their productivity.\n\nAs such monitoring would affect how much an employee is paid, it would have a significant effect on them.\n\nAutomated decision-making that has a legal or similarly significant effect on employees is subject to the rules under Article 22 of the U.K. GDPR.\n\nEmployers can only make such automated decisions where the decision is (1) necessary for the entry into or performance of the employment contract, (2) authorized by the laws that apply to the employer (provided that such laws feature suitable safeguards for the employee\u2019s rights and freedoms), or (3) based on the employee\u2019s explicit consent (which is unlikely to apply in an employer-employee relationship).\n\nThe ICO recommends employers give employees information about the processing, introduce simple ways for employees to request human intervention or challenge an automated decision and carry out checks to ensure that any automated decision-making tools are working as intended.\n\nFeedback on the Guidance Employers can provide their feedback to the guidance by downloading and completing the questionnaire on the ICO website and emailing it to employmentguidance@ico.org.uk .\n\nThe deadline for submissions is January 11, 2023.\n\nKey Takeaways Employee monitoring is an enforcement priority for European supervisory authorities.\n\nFor example, on March 31, 2022, the ICO concluded an investigation into employee monitoring by a major financial institution.\n\nWhile the ICO did not take enforcement action against the company, it recommended that it conduct a DPIA in relation to any employee monitoring tools used.\n\nAdditionally, in 2020, Hamburg, Germany\u2019s Commissioner for Data Protection and Freedom of Information fined a worldwide clothing retailer \u20ac35.3 million for employee recording practices."
    ]
}